{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dee559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and transform MIT-BIH dataset from Zip file\n",
    "!python3 extract-data.py\n",
    "!python3 transform-data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121ee4e5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "95bf22c5",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8f38d1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "f5a534e2",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "# Switch to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea81f73",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "3c7597db",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Dataloader classes\n",
    "class EcgDataset(Dataset):\n",
    "    def __init__(self, source):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load training data\n",
    "        self.train_x = torch.from_numpy(np.load(f\"data/{source}_x.npy\")).float()\n",
    "        self.train_y = torch.from_numpy(np.load(f\"data/{source}_y.npy\")).float()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.train_x[index], self.train_y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a328801",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "80a6415a",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders (change num_workers=0 if CPU only)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=EcgDataset(\"train\"), batch_size=32, shuffle=True, num_workers=2, drop_last=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=EcgDataset(\"test\"), batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "test_dataloader_display = DataLoader(\n",
    "    dataset=EcgDataset(\"test\"), batch_size=1, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b24eeb7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "69b9e349",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2fbb1fbb0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph of data to prove dataloaders are working\n",
    "x, y = iter(test_dataloader_display).next()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Electrical Activity')\n",
    "plt.plot(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2e0b60",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "8ce33609",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# LSTM block to be used inside other models\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).to(device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6132b13",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 48,
     "id": "07acd067",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Simple fully connected model to test accuracy against\n",
    "class SimpleFullyConnected(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFullyConnected, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(187, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Linear(1000, 5),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(batch_size, -1)\n",
    "\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714e9cba",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 49,
     "id": "cb20f151",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Slightly more complex model to test accuracy against\n",
    "class ConvolutionalBLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalBLSTM, self).__init__()\n",
    "        # LSTM\n",
    "        self.c1L = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 16, stride=1, padding=0), # BxCxL -> Bx32x172\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.L = LSTMModel(32, 172, 1, 0.0) #BxLxC\n",
    "        self.fcL = nn.Sequential(\n",
    "            nn.Linear(344*172, 5),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(batch_size, 1, -1)\n",
    "        \n",
    "        # First conv LSTM\n",
    "        outL = self.c1L(x)\n",
    "        outL = self.L(outL.reshape(batch_size, outL.size(2), -1))\n",
    "        outL = self.fcL(outL.reshape(batch_size, -1))\n",
    "\n",
    "        return outL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e292f66",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 50,
     "id": "8866f8a5",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# HADLN model\n",
    "class HADLN(nn.Module):\n",
    "    def BasicBlock(self, in_channels=32, out_channels=32, kernel_size=17, stride=1, padding=8):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm1d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, stride=1, padding=padding)\n",
    "        )\n",
    "    \n",
    "    def ShortcutBlock(self, in_channels=32, out_channels=64):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, 1, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HADLN, self).__init__()\n",
    "        # LSTM\n",
    "        self.c1L = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 16, stride=1, padding=0), # BxCxL -> Bx32x172\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.L = LSTMModel(32, 172, 1, 0.0) #BxLxC\n",
    "        self.fcL = nn.Linear(344*172, 256*18)\n",
    "        \n",
    "        # ResNet Precursors\n",
    "        self.c1RP = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 16, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.c2RP = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 16, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(32, 32, 16, stride=1, padding=0)\n",
    "        )\n",
    "        \n",
    "        # ResNet\n",
    "        self.rb1 = self.BasicBlock()\n",
    "        self.rb2 = self.BasicBlock()\n",
    "        self.rb3 = self.BasicBlock()\n",
    "        self.rb4 = self.BasicBlock()\n",
    "        self.sc1 = self.ShortcutBlock()\n",
    "        \n",
    "        self.rb5 = self.BasicBlock(in_channels=32, out_channels=64, stride=2)\n",
    "        self.rb6 = self.BasicBlock(in_channels=64, out_channels=64)\n",
    "        self.rb7 = self.BasicBlock(in_channels=64, out_channels=64)\n",
    "        self.rb8 = self.BasicBlock(in_channels=64, out_channels=64)\n",
    "        self.sc2 = self.ShortcutBlock(in_channels=64, out_channels=128)\n",
    "        \n",
    "        self.rb9 = self.BasicBlock(in_channels=64, out_channels=128, stride=2)\n",
    "        self.rb10 = self.BasicBlock(in_channels=128, out_channels=128)\n",
    "        self.rb11 = self.BasicBlock(in_channels=128, out_channels=128)\n",
    "        self.rb12 = self.BasicBlock(in_channels=128, out_channels=128)\n",
    "        self.sc3 = self.ShortcutBlock(in_channels=128, out_channels=256)\n",
    "        \n",
    "        self.rb13 = self.BasicBlock(in_channels=128, out_channels=256, stride=2)\n",
    "        self.rb14 = self.BasicBlock(in_channels=256, out_channels=256)\n",
    "        self.rb15 = self.BasicBlock(in_channels=256, out_channels=256)\n",
    "        self.rb16 = self.BasicBlock(in_channels=256, out_channels=256)\n",
    "        \n",
    "        # ResNet Fc\n",
    "        self.fcR = nn.Linear(256*18, 256*18)\n",
    "        \n",
    "        # Merge LSTM and ResNet, this is attention as well\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256*18, 256*18),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "        # Output - time distribute\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(4608),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256*18, 5),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(batch_size, 1, -1)\n",
    "        \n",
    "        # First conv LSTM\n",
    "        outL = self.c1L(x)\n",
    "        outL = self.L(outL.reshape(batch_size, outL.size(2), -1))\n",
    "        outL = self.fcL(outL.reshape(batch_size, -1))\n",
    "        \n",
    "        # ResNet precursors\n",
    "        outR = self.c1RP(x)\n",
    "        outR = self.c2RP(outR)\n",
    "        \n",
    "        # ResNet\n",
    "        \n",
    "        # 32 features\n",
    "        outR = self.rb1(outR)\n",
    "        outR = self.rb2(outR) + outR\n",
    "        outR = self.rb3(outR) + outR\n",
    "        outR = self.rb4(outR) + outR\n",
    "        sc = self.sc1(outR)\n",
    "        \n",
    "        # 64 Features\n",
    "        outR = self.rb5(outR) + sc\n",
    "        outR = self.rb6(outR) + outR\n",
    "        outR = self.rb7(outR) + outR\n",
    "        outR = self.rb8(outR) + outR\n",
    "        sc = self.sc2(outR)\n",
    "        \n",
    "        # 128 Features\n",
    "        outR = self.rb9(outR) + sc\n",
    "        outR = self.rb10(outR) + outR\n",
    "        outR = self.rb11(outR) + outR\n",
    "        outR = self.rb12(outR) + outR\n",
    "        sc = self.sc3(outR)\n",
    "        \n",
    "        # 256 Features\n",
    "        outR = self.rb13(outR) + sc\n",
    "        outR = self.rb14(outR) + outR\n",
    "        outR = self.rb15(outR) + outR\n",
    "        outR = (self.rb16(outR) + outR).reshape(batch_size, -1)\n",
    "        rnFeatures = outR\n",
    "\n",
    "        # ResNet FC\n",
    "        outR = self.fcR(outR)\n",
    "        \n",
    "        # Merge\n",
    "        merge = self.merge(outL + outR)\n",
    "        \n",
    "        # Multiply by ResNet output\n",
    "        merge = merge * rnFeatures\n",
    "        \n",
    "        # Classifier\n",
    "        classifier = self.classifier(merge)\n",
    "\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490cad06",
   "metadata": {
    "gradient": {
     "execution_count": 51,
     "id": "8243d752",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Focal loss for handling extremely unbalanced datasets\n",
    "# Taken from:\n",
    "# https://github.com/gokulprasadthekkel/pytorch-multi-class-focal-loss/blob/master/focal_loss.py\n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bde46a9",
   "metadata": {
    "gradient": {
     "execution_count": 52,
     "id": "909e776b",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "def testLoss(model):\n",
    "    criterion = FocalLoss(weight=torch.tensor([1-72470/87553, 1-2223/87553, 1-5788/87553, 1-641/87553, 1-6431/87553]).to(device))\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # get predictions\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29949e1e",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 53,
     "id": "3ac79b00",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epochs):\n",
    "    criterion = FocalLoss(weight=torch.tensor([1-72470/87553, 1-2223/87553, 1-5788/87553, 1-641/87553, 1-6431/87553]).to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    print(f\"Training {epochs} epochs. Dataset is {len(train_dataloader)} big. Using batch size 32\")\n",
    "    print(f\"{len(train_dataloader) // 32 + 1} minibatches are needed per epoch\")\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    min_test_loss = (0, 9999999999999)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Minibatch {i+1}. Loss {loss.item()}\")\n",
    "\n",
    "        # print statistics\n",
    "        print(f\"Epoch {epoch}/{epochs}. Loss {running_loss}\")\n",
    "        test_loss = testLoss(model)\n",
    "        print(f\"Test loss {test_loss}\")\n",
    "        \n",
    "        # Increment scheduler\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Save statistics\n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Save model if loss low\n",
    "        if test_loss < min_test_loss[1]:\n",
    "            min_test_loss = (epoch, test_loss)\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09d93a82",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 54,
     "id": "09cf32b0",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = HADLN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a36ebfda",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 55,
     "id": "73deb129",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model.load_state_dict(torch.load(\"model.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111b835",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 56,
     "id": "f82d5cba",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 25 epochs. Dataset is 2736 big. Using batch size 32\n",
      "86 minibatches are needed per epoch\n",
      "Minibatch 1. Loss 0.06505963951349258\n",
      "Minibatch 1001. Loss 0.09028346091508865\n",
      "Minibatch 2001. Loss 0.047040682286024094\n",
      "Epoch 0/25. Loss 138.77292577340268\n",
      "Test loss 39.36207064567134\n",
      "Minibatch 1. Loss 0.06388075649738312\n",
      "Minibatch 1001. Loss 0.025318395346403122\n",
      "Minibatch 2001. Loss 0.08728927373886108\n",
      "Epoch 1/25. Loss 133.09080529608764\n",
      "Test loss 30.313013742212206\n",
      "Minibatch 1. Loss 0.024825606495141983\n",
      "Minibatch 1001. Loss 0.050415657460689545\n",
      "Minibatch 2001. Loss 0.02548980340361595\n",
      "Epoch 2/25. Loss 118.33617493161\n",
      "Test loss 29.07951483828947\n",
      "Minibatch 1. Loss 0.01946282759308815\n",
      "Minibatch 1001. Loss 0.05616622418165207\n",
      "Minibatch 2001. Loss 0.018767062574625015\n",
      "Epoch 3/25. Loss 108.91111539583653\n",
      "Test loss 25.01913564512506\n",
      "Minibatch 1. Loss 0.04392869025468826\n",
      "Minibatch 1001. Loss 0.05262960121035576\n",
      "Minibatch 2001. Loss 0.06187665835022926\n",
      "Epoch 4/25. Loss 89.260361823719\n",
      "Test loss 20.674263547174633\n",
      "Minibatch 1. Loss 0.008265845477581024\n",
      "Minibatch 1001. Loss 0.04606373608112335\n",
      "Minibatch 2001. Loss 0.00773756206035614\n",
      "Epoch 5/25. Loss 85.26894183037803\n",
      "Test loss 20.326964360661805\n",
      "Minibatch 1. Loss 0.027710385620594025\n",
      "Minibatch 1001. Loss 0.014308428391814232\n",
      "Minibatch 2001. Loss 0.04117469862103462\n",
      "Epoch 6/25. Loss 81.67338720988482\n",
      "Test loss 20.369499775581062\n",
      "Minibatch 1. Loss 0.02722756937146187\n",
      "Minibatch 1001. Loss 0.012944454327225685\n",
      "Minibatch 2001. Loss 0.032443612813949585\n",
      "Epoch 7/25. Loss 80.30928760953248\n",
      "Test loss 19.51689340127632\n",
      "Minibatch 1. Loss 0.03906595706939697\n",
      "Minibatch 1001. Loss 0.010476996190845966\n",
      "Minibatch 2001. Loss 0.034025050699710846\n",
      "Epoch 8/25. Loss 78.66155186435208\n",
      "Test loss 19.686755060683936\n",
      "Minibatch 1. Loss 0.03351365402340889\n",
      "Minibatch 1001. Loss 0.040879085659980774\n",
      "Minibatch 2001. Loss 0.00997672975063324\n",
      "Epoch 9/25. Loss 80.5051020826213\n",
      "Test loss 19.431932385079563\n",
      "Minibatch 1. Loss 0.024469362571835518\n",
      "Minibatch 1001. Loss 0.07292698323726654\n",
      "Minibatch 2001. Loss 0.025555133819580078\n",
      "Epoch 10/25. Loss 79.14573651365936\n",
      "Test loss 20.02102291258052\n",
      "Minibatch 1. Loss 0.02712366171181202\n",
      "Minibatch 1001. Loss 0.013087272644042969\n",
      "Minibatch 2001. Loss 0.01958348974585533\n",
      "Epoch 11/25. Loss 76.63641684968024\n",
      "Test loss 19.1244876999408\n",
      "Minibatch 1. Loss 0.02712859772145748\n",
      "Minibatch 1001. Loss 0.0569697804749012\n",
      "Minibatch 2001. Loss 0.026575181633234024\n",
      "Epoch 12/25. Loss 77.05382300494239\n",
      "Test loss 19.502775598317385\n",
      "Minibatch 1. Loss 0.015573348850011826\n",
      "Minibatch 1001. Loss 0.011078910902142525\n",
      "Minibatch 2001. Loss 0.03030477464199066\n",
      "Epoch 13/25. Loss 77.96813602745533\n",
      "Test loss 19.03975106589496\n",
      "Minibatch 1. Loss 0.02129480242729187\n",
      "Minibatch 1001. Loss 0.05635257810354233\n",
      "Minibatch 2001. Loss 0.024374667555093765\n",
      "Epoch 14/25. Loss 78.2130844690837\n",
      "Test loss 19.672213879879564\n",
      "Minibatch 1. Loss 0.014079686254262924\n",
      "Minibatch 1001. Loss 0.03652244061231613\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_losses, test_losses = train(model, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ae262",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 24,
     "id": "34bf0d9a",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Print loss graph\n",
    "plt.plot(test_losses, label=\"Validation\")\n",
    "plt.plot(train_losses, label=\"Training\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Normalized Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a138e",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 58,
     "id": "74ac26a3",
     "kernelId": "cbf3c3c5-e3da-4b9b-b666-9f8d8eddbd04"
    }
   },
   "outputs": [],
   "source": [
    "# Find number of misclassified validation examples\n",
    "import numpy as np\n",
    "with torch.no_grad():\n",
    "    # Precision, accuracy, recall, f1\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1 = []\n",
    "    \n",
    "    # Per class accuracy\n",
    "    correct_by_class = [0,0,0,0,0]\n",
    "    total_by_class = [0,0,0,0,0]\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # get predictions\n",
    "        outputs = model(inputs)\n",
    "        outputs[outputs < 0.5] = 0\n",
    "        outputs[outputs >= 0.5] = 1\n",
    "        \n",
    "        # Find total by class\n",
    "        total_by_class[0] += torch.where((labels[:, 0] == 1))[0].shape[0]\n",
    "        total_by_class[1] += torch.where((labels[:, 1] == 1))[0].shape[0]\n",
    "        total_by_class[2] += torch.where((labels[:, 2] == 1))[0].shape[0]\n",
    "        total_by_class[3] += torch.where((labels[:, 3] == 1))[0].shape[0]\n",
    "        total_by_class[4] += torch.where((labels[:, 4] == 1))[0].shape[0]\n",
    "        \n",
    "        # Find correct by class\n",
    "        correct_by_class[0] += torch.where((labels[:, 0] == outputs[:, 0]) & (labels[:, 0] == 1) )[0].shape[0]\n",
    "        correct_by_class[1] += torch.where((labels[:, 1] == outputs[:, 1]) & (labels[:, 1] == 1) )[0].shape[0]\n",
    "        correct_by_class[2] += torch.where((labels[:, 2] == outputs[:, 2]) & (labels[:, 2] == 1) )[0].shape[0]\n",
    "        correct_by_class[3] += torch.where((labels[:, 3] == outputs[:, 3]) & (labels[:, 3] == 1) )[0].shape[0]\n",
    "        correct_by_class[4] += torch.where((labels[:, 4] == outputs[:, 4]) & (labels[:, 4] == 1) )[0].shape[0]\n",
    "        \n",
    "        # F1\n",
    "        f1.append(f1_score(labels.cpu(), outputs.cpu(), average='weighted', zero_division=0))\n",
    "        \n",
    "        # Precision\n",
    "        precisions.append(precision_score(labels.cpu(), outputs.cpu(), average='weighted', zero_division=0))\n",
    "        \n",
    "        # Recall\n",
    "        recalls.append(recall_score(labels.cpu(), outputs.cpu(), average='weighted', zero_division=0))\n",
    "        \n",
    "# Print accuracy\n",
    "print(f'Total correct: {sum(correct_by_class)} / {sum(total_by_class)}. {sum(correct_by_class) / sum(total_by_class) * 100}%')\n",
    "print(f'{correct_by_class}')\n",
    "print(f'{np.array(correct_by_class) / np.array(total_by_class) * 100}')\n",
    "print('------')\n",
    "\n",
    "# Print precision, recall, and f1\n",
    "print(f'Weighted Precision: {sum(precisions)/len(precisions)*100}%')\n",
    "print(f'Weighted Recall: {sum(recalls)/len(recalls)*100}%')\n",
    "print(f'Weighted F1: {sum(f1)/len(f1)*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fe461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
